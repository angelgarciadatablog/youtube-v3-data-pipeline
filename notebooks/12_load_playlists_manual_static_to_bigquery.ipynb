{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b357246",
   "metadata": {},
   "source": [
    "#  12_load_playlists_manual_static_to_bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29efc8",
   "metadata": {},
   "source": [
    "###  Objetivo\n",
    "\n",
    "Este notebook no genera snapshots hist贸ricos.\n",
    "\n",
    "Su prop贸sito es cargar la tabla estructural playlists_manual_static a BigQuery para permitir joins anal铆ticos con las tablas snapshot.\n",
    "\n",
    "Esta tabla act煤a como dimensi贸n descriptiva de playlists manuales y se reescribe completamente en cada ejecuci贸n del pipeline mensual.  \n",
    "\n",
    "Destino: youtube-datasets-360.angelgarciadatablog.playlists_manual_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a08ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca39ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT\")\n",
    "DATASET_ID = \"angelgarciadatablog\"\n",
    "TABLE_ID = \"playlists_manual_static\"\n",
    "\n",
    "FULL_TABLE_ID = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(\"Destino configurado:\", FULL_TABLE_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25024ee",
   "metadata": {},
   "source": [
    "## П Cargar snapshot desde Parquet (temporal)  \n",
    "\n",
    "锔 Nota temporal:\n",
    "Durante la fase de notebooks, el DataFrame se carga desde Parquet como mecanismo de intercambio entre notebooks.\n",
    "En la versi贸n productiva (scripts .py), el DataFrame se pasar谩 directamente sin almacenamiento intermedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab69ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"youtube\"\n",
    "\n",
    "df_playlists_manual_static = pd.read_parquet(\n",
    "    PROCESSED_PATH / \"playlists_manual_static.parquet\"\n",
    ")\n",
    "\n",
    "df_playlists_manual_static.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlists_manual_static.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a3c56",
   "metadata": {},
   "source": [
    "##  Crear tabla particionada con el esquema y datos del dataframe \n",
    "\n",
    "En este caso definimos el esquema manualmente en lugar de dejar que BigQuery lo infiera autom谩ticamente desde el DataFrame. Esto nos permite controlar expl铆citamente los tipos de datos, especialmente published_at y extracted_at, que queremos almacenar como DATETIME (hora local Per煤) y no como TIMESTAMP. Cuando BigQuery infiere el esquema, puede convertir columnas datetime en TIMESTAMP, lo que introduce interpretaci贸n en UTC. Definir el esquema manualmente garantiza consistencia y evita ambig眉edades en el modelo temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import NotFound\n",
    "from google.cloud.bigquery import SchemaField\n",
    "\n",
    "schema = [\n",
    "    SchemaField(\"playlist_id\", \"STRING\"),\n",
    "    SchemaField(\"channel_id\", \"STRING\"),\n",
    "    SchemaField(\"title\", \"STRING\"),\n",
    "    SchemaField(\"description\", \"STRING\"),\n",
    "    SchemaField(\"item_count\", \"INT64\"),\n",
    "    SchemaField(\"privacy_status\", \"STRING\"),\n",
    "    SchemaField(\"published_at\", \"TIMESTAMP\"),\n",
    "    SchemaField(\"thumbnail_url\", \"STRING\"),\n",
    "    SchemaField(\"playlist_url\", \"STRING\"),\n",
    "    SchemaField(\"extracted_at\", \"TIMESTAMP\"),\n",
    "]\n",
    "\n",
    "try:\n",
    "    client.get_table(FULL_TABLE_ID)\n",
    "    print(\"La tabla ya existe.\")\n",
    "\n",
    "except NotFound:\n",
    "    table = bigquery.Table(FULL_TABLE_ID, schema=schema)\n",
    "    client.create_table(table)\n",
    "    print(\"Tabla creada correctamente.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e177b4",
   "metadata": {},
   "source": [
    "##  Cargar datos del parquet a big query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2锔 Carga los datos desde tu DataFrame hacia BigQuery. WRITE TRUNCATE = sobreescribe los datos\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_TRUNCATE\"\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    df_playlists_manual_static,\n",
    "    FULL_TABLE_ID,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "job.result()\n",
    "\n",
    "print(\"Tabla playlists_manual_static reemplazada correctamente.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
